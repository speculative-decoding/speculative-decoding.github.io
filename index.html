<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>COLING 2025 Tutorial: Speculative Decoding for Efficient LLM Inference</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
              <span style="font-size: 80%">COLING 2025 Tutorial:</span><br />
              Speculative Decoding for Efficient LLM Inference
            </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <table>
            <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="20%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/profile_heming.jpg"></td>
                <td width="20%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/profile_yongqi.jpg"></td>
                <td width="20%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/profile_cunxiao.jpg"></td>
                <td width="20%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/profile_qian.png"></td>
                <td width="20%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/profile_maggie.jpg"></td>
            </tr>
              <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="20%" style="text-align: center"><a href="https://hemingkx.github.io/" style="border-radius: 50%">Heming Xia</a><sup>1</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://liyongqi67.github.io/" style="border-radius: 50%">Yongqi Li</a><sup>1</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://nonvolatilememory.github.io/" style="border-radius: 50%">Cunxiao Du</a><sup>2</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://siviltaram.github.io/" style="border-radius: 50%">Qian Liu</a><sup>3</sup></td>
                <td width="20%" style="text-align: center"><a href="https://www4.comp.polyu.edu.hk/~cswjli/" style="border-radius: 50%">Wenjie Li</a><sup>1</sup></td>
              </tr>
            </table>
            </span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University,</span>
            <span class="author-block"><sup>2</sup>SEA AI Lab</span>
            <span class="author-block"><sup>3</sup>TikTok</span>
          </div>
          <br />
          <div class="is-size-5 publication-authors">
            <b>Sunday, January 19, 09:00 - 12:30 (GST), Tutorial 1</b>
          </div>
	      <div class="is-size-5 publication-authors">
            <b>Abu Dhabi National Exhibition Centre, Capital Suite 7</b>
          </div>
          

          <!--<div class="is-size-5 publication-authors">
            Visit <a target="_blank" href="https://us06web.zoom.us/rec/play/6fqU9YDLoFtWqpk8w8I7oFrszHKW6JkbPVGgHsdPBxa69ecgCxbmfP33asLU3DJ74q5BXqDGR2ycOTFk.93teqylfi_uiViNK?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2FNrYheXPtE5zOlbogmdBg653RIu7RBO1uAsYH2CZt_hacD1jOHksRahGlERHc_Ybs.KGX1cRVtJBQtJf0o">this link</a>
            for the Zoom recording of the tutorial
          </div>-->
          <div class="is-size-6 publication-authors">
            For those who have not registered to COLING: we will release video recordings after the tutorial.
          </div>
          <br />
          <!--<div class="is-size-5 publication-authors">
            QnA: <a href="https://tinyurl.com/retrieval-lm-tutorial" target="_blank"><b>tinyurl.com/retrieval-lm-tutorial</b></a>
          </div>-->
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">About this tutorial</h2>
        <div class="content has-text-justified">
          <p>
            This tutorial presents a comprehensive introduction to Speculative Decoding (SD),
            an advanced technique for LLM inference acceleration that has garnered significant research interest in recent years.
            SD is introduced as an innovative decoding paradigm to mitigate the high inference latency stemming from autoregressive decoding in LLMs.
            At each decoding step, SD efficiently drafts several future tokens and then verifies them in parallel.
            This approach, unlike traditional autoregressive decoding, facilitates the simultaneous decoding of multiple tokens per step,
            thereby achieving promising 2x-4x speedups in LLM inference while maintaining original distributions.
          </p>
          <p>
            This tutorial delves into the latest techniques in SD, including draft model architectures and verification strategies.
            Additionally, it explores the acceleration potential and future research directions in this promising field.
            We aim for this tutorial to elucidate the current research landscape and offer insights for researchers interested in Speculative Decoding,
            ultimately contributing to more efficient LLM inference.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Schedule</h2>
        <p>
          Our tutorial will be held on January 19 (all the times are based on GST = Abu Dhabi local time).
          <!-- <em>Slides may be subject to updates.</em>-->
        </p>

        <div class="content has-text-justified">

          <style type="text/css">
          .tg  {border-collapse:collapse;border-spacing:0;}
          .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
          .tg .tg-0lax{text-align:left;vertical-align:top}
          </style>
          <table class="tg">
          <thead>
            <tr>
              <th class="tg-0pky">Time</th>
              <th class="tg-0lax">Section</th>
              <th class="tg-0lax">Presenter</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-0lax">09:00—09:10</td>
              <td class="tg-0lax">Section 1: Introduction  <!-- <a href="./slides/1-intro.pdf" target='_blank'>[Slides]</a>--></td>
              <td class="tg-0lax">Heming</td>
            </tr>
            <tr>
              <td class="tg-0lax">09:10—09:40</td>
              <td class="tg-0lax">Section 2: Definition & Preliminaries </td>
              <td class="tg-0lax">Heming</td>
            </tr>
            <tr>
              <td class="tg-0lax">09:40—09:55</td>
              <td class="tg-0lax">Section 3: Speculative Decoding: History </td>
              <td class="tg-0lax">Qian</td>
            </tr>
            <tr>
              <td class="tg-0lax">09:55—10:25</td>
              <td class="tg-0lax">Section 4: Speculative Decoding: A Taxonomy of Methods </td>
              <td class="tg-0lax">Qian</td>
            </tr>
            <tr>
              <td class="tg-0lax">10:25—10:30</td>
              <td class="tg-0lax">Q & A Session I</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">10:30—11:00</td>
              <td class="tg-0lax">Coffee break</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">11:00—11:40</td>
              <td class="tg-0lax">Section 5: Speculative Decoding: Cutting-edge Algorithms </td>
              <td class="tg-0lax">Heming</td>
            </tr>
            <tr>
              <td class="tg-0lax">11:40—12:10</td>
              <td class="tg-0lax">Section 6: Speculative Decoding: Downstream Adaptations </td>
              <td class="tg-0lax">Yongqi</td>
            </tr>
            <tr>
              <td class="tg-0lax">12:10—12:20</td>
              <td class="tg-0lax">Section 7: Challenges & Opportunities</td>
              <td class="tg-0lax">Yongqi</td>
            </tr>
            <tr>
              <td class="tg-0lax">12:20—12:30</td>
              <td class="tg-0lax">Q & A Session II</td>
              <td class="tg-0lax"></td>
            </tr>
          </tbody>
          </table>
        </div>
      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reading List</h2>

        <p><b>Bold papers</b> are discussed in detail during our tutorial.</p>

        <br />
        
        
        <h3 class="title is-5">Section 3: History</h3>

        <ul>
          <li><a href="https://arxiv.org/abs/2002.08909"><b>REALM: Retrieval-Augmented Language Model Pre-Training</b></a> (Guu et al., 2020)</li>
          <li><a href="https://arxiv.org/abs/2305.06983">Active Retrieval Augmented Generation</a> (Jiang et al., 2023)</li>
        </ul>
        
        <br />

        <h3 class="title is-5">Section 4: A Taxonomy of Methods</h3>

        <ul>
          <li><a href="https://arxiv.org/abs/2004.04906"><b>Dense Passage Retrieval for Open-Domain Question Answering</b></a> (Karpukhin et al., 2020)</li>
        </ul>

        <br />

        <h3 class="title is-5">Section 5: Cutting-edge Algorithms</h3>

        <ul>
          <li><a href="https://arxiv.org/abs/2208.03299"><b>Atlas: Few-shot Learning with Retrieval Augmented Language Models</b></a> (Izacard et al., 2022; also in Section 4)</li>
        </ul>

        <br />

        <h3 class="title is-5">Section 6: Downstream Adaptations</h3>
        
        <ul>
          <li><a href="https://arxiv.org/abs/2107.11976">One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval</a> (Asai et al., 2021)</li>
          <li><a href="https://arxiv.org/abs/2211.12561">Retrieval-Augmented Multimodal Language Modeling</a> (Yasunaga et al., 2023)</li>
        </ul>
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ speculative-decoding-tutorial,
  author    = { Xia, Heming and Du, Cunxiao and Li, Yongqi and Liu, Qian and Li, Wenjie },
  title     = { COLING 2025 Tutorial: Speculative Decoding for Efficient LLM Inference },
  journal   = { COLING 2025 },
  year      = { 2025 },
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/speculative-decoding" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
